# æ ‡å‡†åº“å¯¼å…¥
import asyncio
import json
import logging
import os
import sys
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, AsyncGenerator
import httpx

from naga_core.system.config import get_config

logger = logging.getLogger(__name__)

class ConversationCore:
    def __init__(self):
        self.config = get_config()
        self.base_url = self.config.api.base_url
        self.api_key = self.config.api.api_key
        self.model = self.config.api.model
        
    async def chat_with_tools(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        top_p: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> AsyncGenerator[str, None]:
        """
        ä¸æ¨¡å‹å¯¹è¯å¹¶å¤„ç†å·¥å…·è°ƒç”¨
        """
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json"
        }
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"
            
        # æ„å»ºè¯·æ±‚ä½“
        payload = {
            "model": self.model,
            "messages": messages,
            "stream": True
        }
        
        if temperature is not None:
            payload["temperature"] = temperature
        if top_p is not None:
            payload["top_p"] = top_p
        if max_tokens is not None:
            payload["max_tokens"] = max_tokens
            
        full_response = ""
        
        try:
            async with httpx.AsyncClient() as client:
                async with client.stream(
                    "POST", 
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=30.0
                ) as response:
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data_str = line[6:]  # ç§»é™¤ "data: " å‰ç¼€
                            if data_str.strip() == "[DONE]":
                                break
                                
                            try:
                                data = json.loads(data_str)
                                if "choices" in data and len(data["choices"]) > 0:
                                    delta = data["choices"][0].get("delta", {})
                                    content = delta.get("content", "")
                                    if content:
                                        full_response += content
                                        yield content
                            except json.JSONDecodeError:
                                continue
                                
        except Exception as e:
            logger.error(f"Error in chat streaming: {e}")
            yield f"Error: {str(e)}"
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨éœ€è¦å¤„ç†
        if full_response:
            from mcpserver.tool_call_utils import parse_tool_calls, execute_tool_calls
            tool_calls = parse_tool_calls(full_response)
            if tool_calls:
                tool_result = execute_tool_calls(tool_calls)
                yield f"\n\nå·¥å…·è°ƒç”¨ç»“æœï¼š\n{tool_result}"

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
from openai import AsyncOpenAI

# æœ¬åœ°æ¨¡å—å¯¼å…¥
from apiserver.tool_call_utils import tool_call_loop
from system.config import config, AI_NAME
from mcpserver.mcp_manager import get_mcp_manager
from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX
# from thinking import TreeThinkingEngine
# from thinking.config import COMPLEX_KEYWORDS  # å·²åºŸå¼ƒï¼Œä¸å†ä½¿ç”¨

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
def setup_logging():
    """ç»Ÿä¸€é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_level = getattr(logging, config.system.log_level.upper(), logging.INFO)
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler(sys.stderr)]
    )
    
    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    for logger_name in ["httpcore.connection", "httpcore.http11", "httpx", "openai._base_client", "asyncio"]:
        logging.getLogger(logger_name).setLevel(logging.WARNING)

setup_logging()
logger = logging.getLogger("NagaConversation")

# å…¨å±€çŠ¶æ€ç®¡ç†
class SystemState:
    """ç³»ç»ŸçŠ¶æ€ç®¡ç†å™¨"""
    _tree_thinking_initialized = False
    _mcp_services_initialized = False
    _voice_enabled_logged = False
    _memory_initialized = False
    _persistent_context_initialized = False

# GRAGè®°å¿†ç³»ç»Ÿå¯¼å…¥
def init_memory_manager():
    """åˆå§‹åŒ–GRAGè®°å¿†ç³»ç»Ÿ"""
    if not config.grag.enabled:
        return None
    
    try:
        from summer_memory.memory_manager import memory_manager
        print("[GRAG] âœ… å¤å›­è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        return memory_manager
    except Exception as e:
        logger.error(f"å¤å›­è®°å¿†ç³»ç»ŸåŠ è½½å¤±è´¥: {e}")
        return None

memory_manager = init_memory_manager()

# å·¥å…·å‡½æ•°
def now():
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return time.strftime('%H:%M:%S:') + str(int(time.time() * 1000) % 10000)

_builtin_print = print
def print(*a, **k):
    """è‡ªå®šä¹‰æ‰“å°å‡½æ•°"""
    return sys.stderr.write('[print] ' + (' '.join(map(str, a))) + '\n')

class NagaConversation:  # å¯¹è¯ä¸»ç±»
    def __init__(self):
        self.mcp = get_mcp_manager()
        self.messages = []
        self.dev_mode = False
        # âœ… ä¿®æ­£ï¼šå»æ‰å¤šä½™çš„ '/'ï¼Œé¿å… .../v1//chat/completions
        self.async_client = AsyncOpenAI(
            api_key=config.api.api_key,
            base_url=config.api.base_url.rstrip('/')
        )
        
        # åˆå§‹åŒ–MCPæœåŠ¡ç³»ç»Ÿ
        self._init_mcp_services()
        
        # åˆå§‹åŒ–GRAGè®°å¿†ç³»ç»Ÿï¼ˆåªåœ¨é¦–æ¬¡åˆå§‹åŒ–æ—¶æ˜¾ç¤ºæ—¥å¿—ï¼‰
        self.memory_manager = memory_manager
        if self.memory_manager and not SystemState._memory_initialized:
            logger.info("å¤å›­è®°å¿†ç³»ç»Ÿå·²åˆå§‹åŒ–")
            SystemState._memory_initialized = True
        
        # åˆå§‹åŒ–æŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼ˆåªåœ¨é¦–æ¬¡åˆå§‹åŒ–æ—¶æ˜¾ç¤ºæ—¥å¿—ï¼‰
        if config.api.persistent_context and not SystemState._persistent_context_initialized:
            self._load_persistent_context()
            SystemState._persistent_context_initialized = True
        
        # åˆå§‹åŒ–è¯­éŸ³å¤„ç†ç³»ç»Ÿ
        self.voice = None
        if config.system.voice_enabled:
            try:
                if not SystemState._voice_enabled_logged:
                    logger.info("è¯­éŸ³åŠŸèƒ½å·²å¯ç”¨ï¼ˆè¯­éŸ³è¾“å…¥+è¾“å‡ºï¼‰ï¼Œç”±UIå±‚ç®¡ç†")
                    SystemState._voice_enabled_logged = True
            except Exception as e:
                logger.warning(f"è¯­éŸ³ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
                self.voice = None
        
        # ç¦ç”¨æ ‘çŠ¶æ€è€ƒç³»ç»Ÿ
        self.tree_thinking = None

    def _load_persistent_context(self):
        """ä»æ—¥å¿—æ–‡ä»¶åŠ è½½å†å²å¯¹è¯ä¸Šä¸‹æ–‡"""
        if not config.api.context_parse_logs:
            return
            
        try:
            from logs.log_context_parser import get_log_parser
            parser = get_log_parser()
            
            # è®¡ç®—æœ€å¤§æ¶ˆæ¯æ•°é‡
            max_messages = config.api.max_history_rounds * 2
            
            # åŠ è½½å†å²å¯¹è¯
            recent_messages = parser.load_recent_context(
                days=config.api.context_load_days,
                max_messages=max_messages
            )
            
            if recent_messages:
                self.messages = recent_messages
                logger.info(f"âœ… ä»æ—¥å¿—æ–‡ä»¶åŠ è½½äº† {len(self.messages)} æ¡å†å²å¯¹è¯")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats = parser.get_context_statistics(config.api.context_load_days)
                logger.info(f"ğŸ“Š ä¸Šä¸‹æ–‡ç»Ÿè®¡: {stats['total_files']}ä¸ªæ–‡ä»¶, {stats['total_messages']}æ¡æ¶ˆæ¯")
            else:
                logger.info("ğŸ“ æœªæ‰¾åˆ°å†å²å¯¹è¯è®°å½•ï¼Œå°†å¼€å§‹æ–°çš„å¯¹è¯")
                
        except ImportError:
            logger.warning("âš ï¸ æ—¥å¿—è§£æå™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡æŒä¹…åŒ–ä¸Šä¸‹æ–‡åŠ è½½")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æŒä¹…åŒ–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            # å¤±è´¥æ—¶ä¸å½±å“æ­£å¸¸ä½¿ç”¨ï¼Œç»§ç»­ä½¿ç”¨ç©ºä¸Šä¸‹æ–‡

    def _init_mcp_services(self):
        """åˆå§‹åŒ–MCPæœåŠ¡ç³»ç»Ÿï¼ˆåªåœ¨é¦–æ¬¡åˆå§‹åŒ–æ—¶è¾“å‡ºæ—¥å¿—ï¼Œåç»­é™é»˜ï¼‰"""
        if SystemState._mcp_services_initialized:
            # é™é»˜è·³è¿‡ï¼Œä¸è¾“å‡ºä»»ä½•æ—¥å¿—
            return
        try:
            # è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰MCPæœåŠ¡å’Œhandoff
            self.mcp.auto_register_services()
            logger.info("MCPæœåŠ¡ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            SystemState._mcp_services_initialized = True
            
            # å¼‚æ­¥å¯åŠ¨NagaPortalè‡ªåŠ¨ç™»å½•
            self._start_naga_portal_auto_login()
            
            # å¼‚æ­¥å¯åŠ¨ç‰©è”ç½‘é€šè®¯è¿æ¥çŠ¶æ€æ£€æŸ¥
            self._start_mqtt_status_check()
        except Exception as e:
            logger.error(f"MCPæœåŠ¡ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _start_naga_portal_auto_login(self):
        """å¯åŠ¨NagaPortalè‡ªåŠ¨ç™»å½•ï¼ˆå¼‚æ­¥ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦é…ç½®äº†NagaPortal
            if not config.naga_portal.username or not config.naga_portal.password:
                return  # é™é»˜è·³è¿‡ï¼Œä¸è¾“å‡ºæ—¥å¿—
            
            # åœ¨æ–°çº¿ç¨‹ä¸­å¼‚æ­¥æ‰§è¡Œç™»å½•
            def run_auto_login():
                try:
                    import sys
                    import os
                    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
                    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    sys.path.insert(0, project_root)
                    
                    from mcpserver.agent_naga_portal.portal_login_manager import auto_login_naga_portal
                    
                    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    
                    try:
                        # æ‰§è¡Œè‡ªåŠ¨ç™»å½•
                        result = loop.run_until_complete(auto_login_naga_portal())
                        
                        if result['success']:
                            # ç™»å½•æˆåŠŸï¼Œæ˜¾ç¤ºçŠ¶æ€
                            print("âœ… NagaPortalè‡ªåŠ¨ç™»å½•æˆåŠŸ")
                            self._show_naga_portal_status()
                        else:
                            # ç™»å½•å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯
                            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                            print(f"âŒ NagaPortalè‡ªåŠ¨ç™»å½•å¤±è´¥: {error_msg}")
                            self._show_naga_portal_status()
                    finally:
                        loop.close()
                        
                except Exception as e:
                    # ç™»å½•å¼‚å¸¸ï¼Œæ˜¾ç¤ºé”™è¯¯
                    print(f"âŒ NagaPortalè‡ªåŠ¨ç™»å½•å¼‚å¸¸: {e}")
                    self._show_naga_portal_status()
            
            # å¯åŠ¨åå°çº¿ç¨‹
            import threading
            login_thread = threading.Thread(target=run_auto_login, daemon=True)
            login_thread.start()
            
        except Exception as e:
            # å¯åŠ¨å¼‚å¸¸ï¼Œæ˜¾ç¤ºé”™è¯¯
            print(f"âŒ NagaPortalè‡ªåŠ¨ç™»å½•å¯åŠ¨å¤±è´¥: {e}")
            self._show_naga_portal_status()

    def _show_naga_portal_status(self):
        """æ˜¾ç¤ºNagaPortalçŠ¶æ€ï¼ˆç™»å½•å®Œæˆåè°ƒç”¨ï¼‰"""
        try:
            from mcpserver.agent_naga_portal.portal_login_manager import get_portal_login_manager
            login_manager = get_portal_login_manager()
            status = login_manager.get_status()
            cookies = login_manager.get_cookies()
            
            print(f"ğŸŒ NagaPortalçŠ¶æ€:")
            print(f"   åœ°å€: {config.naga_portal.portal_url}")
            print(f"   ç”¨æˆ·: {config.naga_portal.username[:3]}***{config.naga_portal.username[-3:] if len(config.naga_portal.username) > 6 else '***'}")
            
            if cookies:
                print(f"ğŸª Cookieä¿¡æ¯ ({len(cookies)}ä¸ª):")
                for name, value in cookies.items():
                    print(f"   {name}: {value}")
            else:
                print(f"ğŸª Cookie: æœªè·å–åˆ°")
            
            user_id = status.get('user_id')
            if user_id:
                print(f"ğŸ‘¤ ç”¨æˆ·ID: {user_id}")
            else:
                print(f"ğŸ‘¤ ç”¨æˆ·ID: æœªè·å–åˆ°")
                
            # æ˜¾ç¤ºç™»å½•çŠ¶æ€
            if status.get('is_logged_in'):
                print(f"âœ… ç™»å½•çŠ¶æ€: å·²ç™»å½•")
            else:
                print(f"âŒ ç™»å½•çŠ¶æ€: æœªç™»å½•")
                if status.get('login_error'):
                    print(f"   é”™è¯¯: {status.get('login_error')}")
                    
        except Exception as e:
            print(f"ğŸª NagaPortalçŠ¶æ€è·å–å¤±è´¥: {e}")
    
    def _start_mqtt_status_check(self):
        """å¯åŠ¨ç‰©è”ç½‘é€šè®¯è¿æ¥å¹¶æ˜¾ç¤ºçŠ¶æ€ï¼ˆå¼‚æ­¥ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦é…ç½®äº†ç‰©è”ç½‘é€šè®¯
            if not config.mqtt.enabled:
                return  # é™é»˜è·³è¿‡ï¼Œä¸è¾“å‡ºæ—¥å¿—
            
            # åœ¨æ–°çº¿ç¨‹ä¸­å¼‚æ­¥æ‰§è¡Œç‰©è”ç½‘é€šè®¯è¿æ¥
            def run_mqtt_connection():
                try:
                    import sys
                    import os
                    import time
                    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
                    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    sys.path.insert(0, project_root)
                    
                    try:
                        from mqtt_tool.device_switch import device_manager
                        
                        # å°è¯•è¿æ¥ç‰©è”ç½‘è®¾å¤‡
                        if hasattr(device_manager, 'connect'):
                            success = device_manager.connect()
                            if success:
                                print("ğŸ”— ç‰©è”ç½‘é€šè®¯çŠ¶æ€: å·²è¿æ¥")
                            else:
                                print("âš ï¸ ç‰©è”ç½‘é€šè®¯çŠ¶æ€: è¿æ¥å¤±è´¥ï¼ˆå°†åœ¨ä½¿ç”¨æ—¶é‡è¯•ï¼‰")
                        else:
                            print("âŒ ç‰©è”ç½‘é€šè®¯åŠŸèƒ½ä¸å¯ç”¨")
                            
                    except Exception as e:
                        print(f"âš ï¸ ç‰©è”ç½‘é€šè®¯è¿æ¥å¤±è´¥: {e}")
                        
                except Exception as e:
                    print(f"âŒ ç‰©è”ç½‘é€šè®¯è¿æ¥å¼‚å¸¸: {e}")
            
            # å¯åŠ¨åå°çº¿ç¨‹
            import threading
            mqtt_thread = threading.Thread(target=run_mqtt_connection, daemon=True)
            mqtt_thread.start()
            
        except Exception as e:
            print(f"âŒ ç‰©è”ç½‘é€šè®¯è¿æ¥å¯åŠ¨å¤±è´¥: {e}")
    
    def save_log(self, u, a):  # ä¿å­˜å¯¹è¯æ—¥å¿—
        if self.dev_mode:
            return  # å¼€å‘è€…æ¨¡å¼ä¸å†™æ—¥å¿—
        d = datetime.now().strftime('%Y-%m-%d')
        t = datetime.now().strftime('%H:%M:%S')
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = config.system.log_dir
        if not os.path.exists(log_dir):
            os.makedirs(log_dir, exist_ok=True)
            logger.info(f"å·²åˆ›å»ºæ—¥å¿—ç›®å½•: {log_dir}")
        
        # ä¿å­˜å¯¹è¯æ—¥å¿—
        log_file = os.path.join(log_dir, f"{d}.log")
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(f"[{t}] ç”¨æˆ·: {u}\n")
                f.write(f"[{t}] {AI_NAME}: {a}\n")
                f.write("-" * 50 + "\n")
        except Exception as e:
            logger.error(f"ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")
    
    def _format_services_for_prompt(self, available_services: dict) -> str:
        """æ ¼å¼åŒ–å¯ç”¨æœåŠ¡åˆ—è¡¨ä¸ºpromptå­—ç¬¦ä¸²ï¼ŒMCPæœåŠ¡å’ŒAgentæœåŠ¡åˆ†å¼€ï¼ŒåŒ…å«å…·ä½“è°ƒç”¨æ ¼å¼"""
        mcp_services = available_services.get("mcp_services", [])
        agent_services = available_services.get("agent_services", [])
        
        # è·å–æœ¬åœ°åŸå¸‚ä¿¡æ¯å’Œå½“å‰æ—¶é—´
        local_city = "æœªçŸ¥åŸå¸‚"
        current_time = ""
        try:
            # ä»WeatherTimeAgentè·å–æœ¬åœ°åŸå¸‚ä¿¡æ¯
            from mcpserver.agent_weather_time.agent_weather_time import WeatherTimeTool
            weather_tool = WeatherTimeTool()
            local_city = getattr(weather_tool, '_local_city', 'æœªçŸ¥åŸå¸‚') or 'æœªçŸ¥åŸå¸‚'
            
            # è·å–å½“å‰æ—¶é—´
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        except Exception as e:
            print(f"[DEBUG] è·å–æœ¬åœ°ä¿¡æ¯å¤±è´¥: {e}")
        
        # æ ¼å¼åŒ–MCPæœåŠ¡åˆ—è¡¨ï¼ŒåŒ…å«å…·ä½“è°ƒç”¨æ ¼å¼
        mcp_list = []
        for service in mcp_services:
            name = service.get("name", "")
            description = service.get("description", "")
            display_name = service.get("display_name", name)
            tools = service.get("available_tools", [])
            
            # å±•ç¤ºname+displayName
            if description:
                mcp_list.append(f"- {name}: {description}")
            else:
                mcp_list.append(f"- {name}")
            
            # ä¸ºæ¯ä¸ªå·¥å…·æ˜¾ç¤ºå…·ä½“è°ƒç”¨æ ¼å¼
            if tools:
                for tool in tools:
                    tool_name = tool.get('name', '')
                    tool_desc = tool.get('description', '')
                    tool_example = tool.get('example', '')
                    
                    if tool_name and tool_example:
                        # è§£æç¤ºä¾‹JSONï¼Œæå–å‚æ•°
                        try:
                            import json
                            example_data = json.loads(tool_example)
                            params = []
                            for key, value in example_data.items():
                                if key != 'tool_name':
                                    params.append(f"{key}: {value}")  # ä¸å†éœ€è¦å¯¹å¤©æ°”è¿›è¡Œç‰¹æ®Šå¤„ç†
                            
                            # æ„å»ºè°ƒç”¨æ ¼å¼
                            format_str = f"  {tool_name}: ï½›\n"
                            format_str += f"    \"agentType\": \"mcp\",\n"
                            format_str += f"    \"service_name\": \"{name}\",\n"
                            format_str += f"    \"tool_name\": \"{tool_name}\",\n"
                            for param in params:
                                # å°†ä¸­æ–‡å‚æ•°åè½¬æ¢ä¸ºè‹±æ–‡
                                param_key, param_value = param.split(': ', 1)
                                format_str += f"    \"{param_key}\": \"{param_value}\",\n"
                            format_str += f"  ï½\n"
                            
                            mcp_list.append(format_str)
                        except:
                            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
                            mcp_list.append(f"  {tool_name}: ä½¿ç”¨tool_nameå‚æ•°è°ƒç”¨")
        
        # æ ¼å¼åŒ–AgentæœåŠ¡åˆ—è¡¨
        agent_list = []
        
        # 1. æ·»åŠ handoffæœåŠ¡
        for service in agent_services:
            name = service.get("name", "")
            description = service.get("description", "")
            tool_name = service.get("tool_name", "agent")
            display_name = service.get("display_name", name)
            # å±•ç¤ºname+displayName
            if description:
                agent_list.append(f"- {name}(å·¥å…·å: {tool_name}): {description}")
            else:
                agent_list.append(f"- {name}(å·¥å…·å: {tool_name})")
        
        # 2. ç›´æ¥ä»AgentManagerè·å–å·²æ³¨å†Œçš„Agent
        try:
            from mcpserver.agent_manager import get_agent_manager
            agent_manager = get_agent_manager()
            agent_manager_agents = agent_manager.get_available_agents()
            
            for agent in agent_manager_agents:
                name = agent.get("name", "")
                base_name = agent.get("base_name", "")
                description = agent.get("description", "")
                
                # å±•ç¤ºæ ¼å¼ï¼šbase_name: æè¿°
                if description:
                    agent_list.append(f"- {base_name}: {description}")
                else:
                    agent_list.append(f"- {base_name}")
                    
        except Exception as e:
            # å¦‚æœAgentManagerä¸å¯ç”¨ï¼Œé™é»˜å¤„ç†
            pass
        
        # æ·»åŠ æœ¬åœ°ä¿¡æ¯è¯´æ˜
        local_info = f"\n\nã€å½“å‰ç¯å¢ƒä¿¡æ¯ã€‘\n- æœ¬åœ°åŸå¸‚: {local_city}\n- å½“å‰æ—¶é—´: {current_time}\n\nã€ä½¿ç”¨è¯´æ˜ã€‘\n- å¤©æ°”/æ—¶é—´æŸ¥è¯¢æ—¶ï¼Œè¯·ä½¿ç”¨ä¸Šè¿°æœ¬åœ°åŸå¸‚ä¿¡æ¯ä½œä¸ºcityå‚æ•°\n- æ‰€æœ‰æ—¶é—´ç›¸å…³æŸ¥è¯¢éƒ½åŸºäºå½“å‰ç³»ç»Ÿæ—¶é—´"
        
        # è¿”å›æ ¼å¼åŒ–çš„æœåŠ¡åˆ—è¡¨
        result = {
            "available_mcp_services": "\n".join(mcp_list) + local_info if mcp_list else "æ— " + local_info,
            "available_agent_services": "\n".join(agent_list) if agent_list else "æ— "
        }
        
        return result

    async def process(self, u, is_voice_input=False):  # æ·»åŠ is_voice_inputå‚æ•°
        try:
            # å¼€å‘è€…æ¨¡å¼ä¼˜å…ˆåˆ¤æ–­
            if u.strip().lower() == "#devmode":
                self.dev_mode = not self.dev_mode  # åˆ‡æ¢æ¨¡å¼
                status = "è¿›å…¥" if self.dev_mode else "é€€å‡º"
                yield (AI_NAME, f"å·²{status}å¼€å‘è€…æ¨¡å¼")
                return

            # åªåœ¨è¯­éŸ³è¾“å…¥æ—¶æ˜¾ç¤ºå¤„ç†æç¤º
            if is_voice_input:
                print(f"å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥ï¼š{now()}")  # è¯­éŸ³è½¬æ–‡æœ¬ç»“æŸï¼Œå¼€å§‹å¤„ç†
                     
            # è·å–è¿‡æ»¤åçš„æœåŠ¡åˆ—è¡¨
            available_services = self.mcp.get_available_services_filtered()
            services_text = self._format_services_for_prompt(available_services)
            
            # æ·»åŠ handoffæç¤ºè¯ - å…ˆè·å–æœåŠ¡ä¿¡æ¯å†æ ¼å¼åŒ–
            system_prompt = f"{RECOMMENDED_PROMPT_PREFIX}\n{config.prompts.naga_system_prompt.format(ai_name=AI_NAME, **services_text)}"
            
            # ä½¿ç”¨æ¶ˆæ¯ç®¡ç†å™¨ç»Ÿä¸€çš„æ¶ˆæ¯æ‹¼æ¥é€»è¾‘ï¼ˆUIç•Œé¢ä½¿ç”¨ï¼‰
            from apiserver.message_manager import message_manager
            msgs = message_manager.build_conversation_messages_from_memory(
                memory_messages=self.messages,
                system_prompt=system_prompt,
                current_message=u,
                max_history_rounds=config.api.max_history_rounds
            )

            print(f"GTPè¯·æ±‚å‘é€ï¼š{now()}")  # AIè¯·æ±‚å‰
            
            # æµå¼å¤„ç†ï¼šå®æ—¶æ£€æµ‹å·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨å¾ªç¯
            try:
                # å¯¼å…¥æµå¼å·¥å…·è°ƒç”¨æå–å™¨
                from apiserver.streaming_tool_extractor import StreamingToolCallExtractor
                import queue
                
                # åˆ›å»ºå·¥å…·è°ƒç”¨é˜Ÿåˆ—
                tool_calls_queue = queue.Queue()
                tool_extractor = StreamingToolCallExtractor(self.mcp)
                
                # ç”¨äºç´¯ç§¯å‰ç«¯æ˜¾ç¤ºçš„çº¯æ–‡æœ¬ï¼ˆä¸åŒ…å«å·¥å…·è°ƒç”¨ï¼‰
                display_text = ""
                
                # è®¾ç½®å›è°ƒå‡½æ•°
                def on_text_chunk(text: str, chunk_type: str):
                    """å¤„ç†æ–‡æœ¬å— - å‘é€åˆ°å‰ç«¯æ˜¾ç¤º"""
                    if chunk_type == "chunk":
                        nonlocal display_text
                        display_text += text
                        return (AI_NAME, text)
                    return None
                
                def on_sentence(sentence: str, sentence_type: str):
                    """å¤„ç†å®Œæ•´å¥å­"""
                    if sentence_type == "sentence":
                        print(f"å®Œæˆå¥å­: {sentence}")
                    return None
                
                def on_tool_result(result: str, result_type: str):
                    """å¤„ç†å·¥å…·ç»“æœ - ä¸å‘é€åˆ°å‰ç«¯"""
                    if result_type == "tool_result":
                        print(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {result[:100]}...")
                    elif result_type == "tool_error":
                        print(f"âŒ å·¥å…·æ‰§è¡Œé”™è¯¯: {result}")
                    return None
                
                # è®¾ç½®å›è°ƒ
                tool_extractor.set_callbacks(
                    on_text_chunk=on_text_chunk,
                    on_sentence=on_sentence,
                    on_tool_result=on_tool_result,
                    tool_calls_queue=tool_calls_queue
                )
                
                # è°ƒç”¨LLM API - æµå¼æ¨¡å¼
                resp = await self.async_client.chat.completions.create(
                    model=config.api.model,
                    messages=msgs,
                    temperature=config.api.temperature,
                    max_tokens=config.api.max_tokens,
                    stream=True
                )
                
                # === æ–°å¢ï¼šæµå¼å…œåº•å¼€å…³ ===
                saw_any_chunks = False

                # å¤„ç†æµå¼å“åº”
                async for chunk in resp:
                    # åŸå§‹å¢é‡æ—¥å¿—ï¼ˆAI åŸå§‹è¾“å‡ºï¼‰
                    try:
                        delta = getattr(chunk.choices[0], 'delta', None) if chunk.choices else None
                        if delta is not None:
                            logger.info("openai.delta: %r", getattr(delta, 'content', None))
                    except Exception:
                        pass

                    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿chunk.choicesä¸ä¸ºç©ºä¸”æœ‰å†…å®¹
                    if (chunk.choices and 
                        len(chunk.choices) > 0 and 
                        hasattr(chunk.choices[0], 'delta') and 
                        chunk.choices[0].delta.content):
                        content = chunk.choices[0].delta.content
                        saw_any_chunks = True  # âœ… æ”¶åˆ°å¢é‡
                        # ä½¿ç”¨æµå¼å·¥å…·è°ƒç”¨æå–å™¨å¤„ç†å†…å®¹
                        results = await tool_extractor.process_text_chunk(content)
                        if results:
                            for result in results:
                                if isinstance(result, tuple) and len(result) == 2:
                                    yield result
                                elif isinstance(result, str):
                                    yield (AI_NAME, result)
                
                # å®Œæˆå¤„ç†ï¼ˆå…ˆæ”¶å°¾ä¸€æ¬¡ï¼‰
                final_results = await tool_extractor.finish_processing()
                if final_results:
                    for result in final_results:
                        if isinstance(result, tuple) and len(result) == 2:
                            yield result
                        elif isinstance(result, str):
                            yield (AI_NAME, result)

                # === å…œåº•ï¼šæ•´æ®µæµå¼æœªæ”¶åˆ°ä»»ä½•å¢é‡ï¼Œåˆ‡ä¸€æ¬¡éæµå¼æ‹¿å®Œæ•´ç­”æ¡ˆ ===
                if not saw_any_chunks:
                    try:
                        logger.warning("æµå¼æœªæ”¶åˆ°ä»»ä½•å¢é‡ï¼Œåˆ‡æ¢ä¸€æ¬¡éæµå¼å…œåº•ã€‚")
                        non_stream_resp = await self.async_client.chat.completions.create(
                            model=config.api.model,
                            messages=msgs,
                            temperature=config.api.temperature,
                            max_tokens=config.api.max_tokens,
                            stream=False
                        )
                        non_stream_text = non_stream_resp.choices[0].message.content or ""
                        if non_stream_text:
                            results = await tool_extractor.process_text_chunk(non_stream_text)
                            if results:
                                for result in results:
                                    if isinstance(result, tuple) and len(result) == 2:
                                        yield result
                                    elif isinstance(result, str):
                                        yield (AI_NAME, result)
                            # å†æ¬¡æ”¶å°¾
                            final_results = await tool_extractor.finish_processing()
                            if final_results:
                                for result in final_results:
                                    if isinstance(result, tuple) and len(result) == 2:
                                        yield result
                                    elif isinstance(result, str):
                                        yield (AI_NAME, result)
                    except Exception as e:
                        logger.error(f"éæµå¼å…œåº•å¤±è´¥: {e}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨éœ€è¦å¤„ç†
                if not tool_calls_queue.empty():
                    # ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨å¾ªç¯å¤„ç†
                    async def llm_caller(messages, use_stream=False):
                        """LLMè°ƒç”¨å‡½æ•°ï¼Œç”¨äºå·¥å…·è°ƒç”¨å¾ªç¯"""
                        # è¿™é‡Œä¸éœ€è¦å®é™…è°ƒç”¨LLMï¼Œå› ä¸ºå·¥å…·è°ƒç”¨å·²ç»æå–å®Œæˆ
                        return {'content': '', 'status': 'success'}
                    
                    # ä½¿ç”¨å·¥å…·è°ƒç”¨å¾ªç¯å¤„ç†å·¥å…·è°ƒç”¨
                    result = await tool_call_loop(msgs, self.mcp, llm_caller, is_streaming=True, tool_calls_queue=tool_calls_queue)
                    
                    if result.get('has_tool_results'):
                        # æœ‰å·¥å…·æ‰§è¡Œç»“æœï¼Œè®©LLMç»§ç»­å¤„ç†
                        tool_results = result['content']
                        
                        # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„æ¶ˆæ¯ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æ¶ˆæ¯æ‹¼æ¥é€»è¾‘ï¼‰
                        tool_messages = message_manager.build_conversation_messages_from_memory(
                            memory_messages=self.messages,
                            system_prompt=system_prompt,
                            current_message=f"å·¥å…·æ‰§è¡Œç»“æœï¼š{tool_results}",
                            max_history_rounds=config.api.max_history_rounds
                        )
                        
                        # è°ƒç”¨LLMç»§ç»­å¤„ç†å·¥å…·ç»“æœï¼ˆä¿æŒæµå¼ï¼‰
                        try:
                            resp2 = await self.async_client.chat.completions.create(
                                model=config.api.model,
                                messages=tool_messages,
                                temperature=config.api.temperature,
                                max_tokens=config.api.max_tokens,
                                stream=True
                            )
                            
                            # å¤„ç†LLMçš„ç»§ç»­å“åº” - ä¹Ÿéœ€è¦é€šè¿‡æµå¼å·¥å…·è°ƒç”¨æå–å™¨å¤„ç†
                            async for chunk in resp2:
                                # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿chunk.choicesä¸ä¸ºç©ºä¸”æœ‰å†…å®¹
                                if (chunk.choices and 
                                    len(chunk.choices) > 0 and 
                                    hasattr(chunk.choices[0], 'delta') and 
                                    chunk.choices[0].delta.content):
                                    content = chunk.choices[0].delta.content
                                    # ä½¿ç”¨æµå¼å·¥å…·è°ƒç”¨æå–å™¨å¤„ç†å†…å®¹
                                    results = await tool_extractor.process_text_chunk(content)
                                    if results:
                                        for result in results:
                                            if isinstance(result, tuple) and len(result) == 2:
                                                yield result
                                            elif isinstance(result, str):
                                                yield (AI_NAME, result)
                        except Exception as e:
                            print(f"LLMç»§ç»­å¤„ç†å·¥å…·ç»“æœå¤±è´¥: {e}")
                
                # å†æ¬¡æ”¶å°¾ï¼ˆä¿è¯å®Œå…¨æ¸…ç©ºç¼“å†²ï¼‰
                final_results = await tool_extractor.finish_processing()
                if final_results:
                    for result in final_results:
                        if isinstance(result, tuple) and len(result) == 2:
                            yield result
                        elif isinstance(result, str):
                            yield (AI_NAME, result)
                
                # ä¿å­˜å¯¹è¯å†å²ï¼ˆä½¿ç”¨å‰ç«¯æ˜¾ç¤ºçš„çº¯æ–‡æœ¬ï¼‰
                print(f"[DEBUG] æœ€ç»ˆdisplay_texté•¿åº¦: {len(display_text)}")
                print(f"[DEBUG] æœ€ç»ˆdisplay_textå†…å®¹: {display_text[:200]}...")
                self.messages += [{"role": "user", "content": u}, {"role": "assistant", "content": display_text}]
                self.save_log(u, display_text)
                
                # GRAGè®°å¿†å­˜å‚¨ï¼ˆå¼€å‘è€…æ¨¡å¼ä¸å†™å…¥ï¼‰- ä½¿ç”¨å‰ç«¯æ˜¾ç¤ºçš„çº¯æ–‡æœ¬
                if self.memory_manager and not self.dev_mode:
                    try:
                        # ä½¿ç”¨å‰ç«¯æ˜¾ç¤ºçš„çº¯æ–‡æœ¬è¿›è¡Œäº”å…ƒç»„æå–
                        await self.memory_manager.add_conversation_memory(u, display_text)
                    except Exception as e:
                        logger.error(f"GRAGè®°å¿†å­˜å‚¨å¤±è´¥: {e}")
                
            except Exception as e:
                print(f"å·¥å…·è°ƒç”¨å¾ªç¯å¤±è´¥: {e}")
                # åŒºåˆ†APIé”™è¯¯å’ŒMCPé”™è¯¯
                if "API" in str(e) or "api" in str(e) or "HTTP" in str(e) or "è¿æ¥" in str(e):
                    yield (AI_NAME, f"[APIè°ƒç”¨å¼‚å¸¸]: {e}")
                else:
                    yield (AI_NAME, f"[MCPæœåŠ¡å¼‚å¸¸]: {e}")
                return

            return
        except Exception as e:
            import traceback
            traceback.print_exc(file=sys.stderr)
            # åŒºåˆ†APIé”™è¯¯å’ŒMCPé”™è¯¯
            if "API" in str(e) or "api" in str(e) or "HTTP" in str(e) or "è¿æ¥" in str(e):
                yield (AI_NAME, f"[APIè°ƒç”¨å¼‚å¸¸]: {e}")
            else:
                yield (AI_NAME, f"[MCPæœåŠ¡å¼‚å¸¸]: {e}")
            return

    async def get_response(self, prompt: str, temperature: float = 0.7) -> str:
        """ä¸ºæ ‘çŠ¶æ€è€ƒç³»ç»Ÿç­‰æä¾›APIè°ƒç”¨æ¥å£"""  # ç»Ÿä¸€æ¥å£
        try:
            response = await self.async_client.chat.completions.create(
                model=config.api.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=config.api.max_tokens
            )
            return response.choices[0].message.content
        except RuntimeError as e:
            if "handler is closed" in str(e):
                logger.debug(f"å¿½ç•¥è¿æ¥å…³é—­å¼‚å¸¸ï¼Œé‡æ–°åˆ›å»ºå®¢æˆ·ç«¯: {e}")
                # âœ… é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯å¹¶é‡è¯•ï¼ˆåŒæ ·å»æ‰æœ«å°¾ '/'ï¼‰
                self.async_client = AsyncOpenAI(
                    api_key=config.api.api_key,
                    base_url=config.api.base_url.rstrip('/')
                )
                response = await self.async_client.chat.completions.create(
                    model=config.api.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=temperature,
                    max_tokens=config.api.max_tokens
                )
                return response.choices[0].message.content
            else:
                logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
                return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"
        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
            return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"

async def process_user_message(s, msg):
    if config.system.voice_enabled and not msg:  # æ— æ–‡æœ¬è¾“å…¥æ—¶å¯åŠ¨è¯­éŸ³è¯†åˆ«
        async for text in s.voice.stt_stream():
            if text:
                msg = text
                break
        return await s.process(msg, is_voice_input=True)  # è¯­éŸ³è¾“å…¥
    return await s.process(msg, is_voice_input=False)  # æ–‡å­—è¾“å…¥
