# =================================================================
# 甄嬛传CPU训练专用配置文件
# 专为在没有独立显卡的电脑上运行优化
# =================================================================

#----------------------------------------------------------------
# 系统和模型基础配置
#----------------------------------------------------------------
system:
  device: 'cpu'  # 明确指定使用CPU，虽然'auto'也能检测到
  seed: 42

model:
  base_model: 'Qwen/Qwen2-0.5B-Instruct' # 0.5B模型是CPU训练的极限，是正确的选择
  
  # 关键优化：大幅缩短序列长度，这是CPU训练最重要的性能优化之一
  # 128对于CPU来说是一个能跑起来的起点。
  max_length: 128 

#----------------------------------------------------------------
# 数据路径配置
#----------------------------------------------------------------
data:
  # 请确保这里的路径相对于你的运行目录是正确的
  train_file: "../data/processed/train.jsonl"
  validation_file: "../data/processed/validation.jsonl"
  test_file: "../data/processed/test.jsonl"

#----------------------------------------------------------------
# LoRA 参数配置 (保持不变，让模型有学习能力)
#----------------------------------------------------------------
lora:
  enabled: true
  r: 8
  lora_alpha: 16
  lora_dropout: 0.1
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  bias: 'none'

#----------------------------------------------------------------
# 训练核心参数 (CPU 性能优化核心)
#----------------------------------------------------------------
training:
  output_dir: "../training/models/huanhuan_cpu_trained"
  num_train_epochs: 1 # 在CPU上，先尝试只训练1轮，看能否完成

  # --- CPU 关键性能参数 ---
  
  # 1. 混合精度必须禁用
  bf16: false
  fp16: false

  # 2. Batch Size 必须为 1
  # CPU无法像GPU那样并行处理大批量数据，设为1可将内存占用降到最低
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1

  # 3. 梯度累积依然有用，它可以在不增加内存的情况下模拟大批量的效果，让训练更稳定
  gradient_accumulation_steps: 8

  # 4. 梯度检查点，必须开启以节省内存
  gradient_checkpointing: true

  # 5. 数据加载器必须使用单线程
  dataloader_num_workers: 0

  # --- 其他训练参数 ---
  learning_rate: 5e-5 # CPU训练不稳定，使用一个更小的学习率
  weight_decay: 0.01
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"
  max_grad_norm: 1.0

  logging_steps: 5    # 更频繁地打印日志，让你能感知到它还在运行
  eval_strategy: "steps"
  eval_steps: 100     # 减少评估频率，因为评估也很慢
  save_strategy: "steps"
  save_steps: 200     # 减少保存频率

  load_best_model_at_end: false # CPU训练时间太长，先不开启此功能以简化流程
  report_to: [] # 禁用所有报告，减少不必要的开销